---
title: "Measuring, visualizing, and simulating spatial autocorrelation"
author: "Connor Donegan"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{measuring-sa}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.align = "center",
  fig.height = 2.5,
  fig.width = 3.5,
  comment = "#>"
)
#> run with:  sudo Rscript -e "rmarkdown::render('measuring-sa.Rmd')"
```

This vignette covers basic usage of the `geostan` package for measuring, visualizing, and simulating spatial autocorrelation (SA). SA can be defined as systematic spatial patterning in the level of a variable. Positive SA is the tendency for nearby values to be more similar than distant values (i.e. clustering) while negative SA is the tendency for values to be located some distance away from others like them (i.e. repulsion).

## Getting started

Start by loading the `geostan`, `sf`, and `ggplot2` packages into your R environment along with the `ohio` dataset:

```{r message=FALSE, warning = FALSE}
library(geostan)
library(ggplot2)
library(sf)
data(ohio)
```

`geostan::ohio` is a simple features object with county-level Presidential vote shares compiled by the MIT Election Data and Science Lab (2018) and joined to some county characteristics. The data was analyzed using `geostan` in  Donegan et al. (2020). The dataset includes growth in the Republican (GOP) share of Presidential votes from the average preceding elections (2000-2012) to 2016 (`gop_growth`). Thus positive values of `gop_growth` indicate places where Trump improved upon the previous GOP performance and negative values show where he performed worse:

```{r}
ggplot(ohio) +
  geom_sf(aes(fill = gop_growth)) +
  scale_fill_gradient2() +
  theme_void()
```

## Spatial weights matrices

All of the spatial diagnostics and models in `geostan require a spatial connectivity matrix. You can make a connectivity matrix by passing a `SpatialPolygons` or `sf` object to the `shape2mat` function. (It mainly wraps around a couple functions from the `spdep` package). The second argument to `geostan::shape2mat` is the scheme for encoding connectivity---"B", the default, produces a binary scheme (1 for neighbors, else 0) and "W" is row-standardized. 

```{r}
C <- shape2mat(ohio, "B")
W <- shape2mat(ohio, "W")
all(rowSums(W) == 1)
```
The `geostan::shape2mat` function can also create space-time connectivity matrices which many `geostan` functions will accept without any further modification---but you must ensure your data is properly ordered in space and time to match the connectivity matrix.

## Measuring spatial autocorrelation

`geostan` has the following functions for measuring spatial autocorrelation:

- the Moran scatter plot `geostan::moran_plot`.
- the Moran coefficient `geostan::mc`,
- local indicator of spatial autocorrelation `geostan::lisa`,
- the APLE statistic `geostan::aple` (Approximate Profile Likelihood Estimator of the spatial autocorrelation parameter from a simultaneous autoregressive model). Note that the `aple` is an approximation that is only valid for relatively small sample sizes.[^1]

[^1]: As a rough rule of thumb, if you have to wait for the `aple` to calculate, you should be using a different measure.

When using the row-standardized spatial weights matrix, the Moran plot will show the original values `y` after being centered---`y.c = y - mean(y)`---plotted against the mean spatially-laged value (`W %*% y.c`). In this case the regression line is equal to the Moran coefficient:[^2]

[^2]: Using centered data $y_c$ and its spatial lag $\tilde{y_c} = W * y_c$, the Moran coefficient is equal to a scale factor $\frac{n}{c}$ times $\hat{\beta}$ from a bivariate regression of the spatial lag of $y_c$ on itself, where $c = 1'C1$, with $1$ a column vector of ones (i.e. find the sum of the row sums of the connectivity matrix.) For a row-standardized matrix $c = n$ and so $\frac{n}{c} = 1$. Moran's I can be written as $I = \frac{n}{1'C1}\frac{Cov(y_c, \tilde{y_c})}{Var(y_c)} = \frac{n}{1'C1}\hat{\beta}$.


```{r}
y <- ohio$gop_growth
moran_plot(y, W)
```

If instead, we used the binary coding scheme for the spatial weights matrix then the y-axis ($W * y_c$) would show the *sum* of spatially-lagged values and the Moran coefficient will differ from the regression line.

```{r}
mc(y, W)
mc(y, C)
```

 The Moran plot is divided into quadrants, which lends points in each quadrant the following interpretation:

- Points in the upper-right (1st) quadrant are above-average values surrounded by above-average values (positive SA);
- Points in the upper-left (2nd) quadrant are below-average values surrounded by above-average values (negative SA);
- Points in the bottom-left (3rd) quadrant are below-average values surrounded by below-average values (positive SA);
- Points in the bottom-right (4th) quadrant are above-average values surrounded by below-average values (negative (SA).

Each point is thus a local indicator of spatial autocorrelation (LISA) which are often mapped to identify areas of high or low SA. Following Anselin (1995, Equation 7), the LISA values are simply the product of the value on the x-axis with their corresponding y-axis value; and the mean of all LISAs is proportionate to the Moran coefficient.

```{r}
Lisa <- lisa(y, W)

mean(Lisa)
mc(y, W)

ggplot(ohio) +
  geom_sf(aes(fill = Lisa)) +
  scale_fill_gradient2() +
  theme_void()
```

`geostan::aple` requires the row-standardized spatial weights matrix, and arguably provides a more intuitive estimate of the degree of SA since the SAR model can be used to generate spatially autocorrelated data:

```{r}
aple(y, W)
```
## Simulating spatially autocorrelated data

You can simulate data from the simultaneous autoregressie model (SAR) using the `geostan::sim_sar` function and providing, at minimum, a row-standardized spatial weights matrix `w` and the degree of SA, `rho`:

```{r}
x <- sim_sar(w = W, rho = 0.7)

aple(x, W)

ggplot(ohio) +
  geom_sf(aes(fill = x)) +
  scale_fill_gradient2() +
  theme_void()
```
By default `geostan::sim_sar` will return a single n-length draw from the multivariate normal model (with covariance matrix specified following the SAR model). By setting the argument $m$ to an integer value greater than one `sim_sar` will return an $m \times n$ matrix, with each row holding an n-length draw from the SAR model:

```{r}
X <- sim_sar(m = 5, w = W, rho = 0.7) 
dim(X)
apply(X, 1, aple, w = W)
```

## Spatial diagnostics with `sp_diag`

`geostan::sp_diag` provides visual diagnostics for spatial data:

```{r fig.width = 6.5}
sp_diag(y, ohio)
```

It can also be used for analysis of model residuals. Here we model the mean and variance of `gop_growth` using a Gaussian probability distribution:
 \begin{equation}
  y \sim \text{Guassian}(\mu, \sigma).
  \end{equation}
  
Calculating a probability distribution for parameters $\mu, \sigma$ requires an initial or prior probability be specified for each. By Bayes' theorem, the probability of parameters $\theta$ conditional on the latest data $D$ and our initial information $I$ is proportional the product of two terms: first, the probability of the observations conditional on $\theta$ and $I$, and second, the initial probabity of $\theta$ conditional on $I$ alone:
\begin{equation}
  p(\theta | D, I) \propto p(D | \theta,I) p(\theta|I).
\end{equation}

which is often stated as[^3]

\begin{equation}
 \text{Posterior probability} \propto \text{Likelihood} \times \text{Prior probability}
 \end{equation}
 
Here we will just use the priors provided by `geostan` (as printed out to the console):

[^3]: For more complex models such as the spatial models availabe in `geostan`, a more natural notation is Posterior probability $\propto$ [Process model] $\times$ [Parameter model], which recognizes that the prior can itself be a complex model. This generalizes further to incorporate models of observational error: Posterior probability $\propto$ [Data model] $\times$ [Process model] $\times$ [Parameter model] (Berliner 1996; Cressie and Wikle 2011), which is implemented in geostan models through the `ME` argument.

```{r}
fit <- stan_glm(gop_growth ~ 1, data = ohio, refresh = 0)
```
To examine the residuals, $y - \hat{\mu}$, pass the model to `geostan::sp_diag`:

```{r fig.width = 6.5}
sp_diag(fit, ohio)
```

The `geostan` model returns samples drawn from the posterior probability distribution of $\mu$ (fitted values), which can be accessed using `fitted(fit)`. Here $\hat{\mu}$ represents the mean of the posterior distribution of the parameter $\mu$. Thus the following code reproduces the above results, but more transparently:

```{r fig.width = 6.5}
mu <- fitted(fit)
deviations <- y - mu$mean
sp_diag(deviations, ohio)

## also the same:
## mu <- as.matrix(fit, pars = "fitted")
## mu <- apply(mu, 2, mean)
## deviations <- y - mu
## sp_diag(deviations, ohio)
```

## Estimating and visualizing SA patterns

The `geostan` package also provides the `geostan::spatial` method for extracting the spatial trend component from fitted spatial models (`stan_esf`, `stan_icar`, and `stan_car`). Continuous data can be modeled using eigenvector spatial filtering (ESF) models. ESF models use a linear combination of the eigenvectors $E$ of a transformed spatial connectivity matrix $C$ to identify SA patterns in the data. Each eigenvector contains a distinct map pattern which is indexed by the Moran coefficient (proportional to each respective eigenvalue). `geostan` assigns a horseshoe prior model to the parameter vector $\beta_{E}$, reflecting our initial expectation that a relatively small number of eigenvectors will be sufficient to describe the SA patterns in the data. The result is a spatially varying mean $\mu_i$:

\begin{equation}
  \mu_i = \alpha + E_i * \beta_{EV}
\end{equation}

```{r fig.width = 6.5}
fit.esf <- stan_esf(gop_growth ~ 1, data = ohio, C = C, refresh = 0, chains = 4, cores = 4)
sp_diag(fit.esf, ohio)
```
The residuals are no longer auto-correlated (a small negative MC value is expected). Instead, the autocorrelation structure has been shifted to the spatial filter. We can extract the spatial filter with the `spatial` method:

```{r}
mu.esf <- spatial(fit.esf)$mean

ggplot(ohio) +
  geom_sf(aes(fill = mu.esf)) +
  scale_fill_gradient2() +
  theme_void()
```

## References

Anselin, Luc (1995). "Local indicators of spatial association—LISA." *Geographical Analysis* 27, no. 2: 93-115.

Berliner, L. Mark (1996). "Hierarchical Bayesian time-series models" in *Maximum Entropy and Bayesian Methods,* Eds. Hanson, Kenneth M. and Silver, Richard N. Springer Netherlands.

Bivand R, Wong DWS (2018). “Comparing implementations of global and local indicators of spatial association.” *TEST*, 27(3), 716–748. https://doi.org/10.1007/s11749-018-0599-x.

Chun, Yongwan, and Daniel A. Griffith (2013). *Spatial statistics and geostatistics: theory and applications for geographic information science and technology*. Sage.

Cressie, Noel and Wikle, Christopher K. (2011). *Statistics for Spatio-Temporal Data.* Wiley.

Donegan, Connor, Yongwan chun and Amy E. Hughes (2020). “Bayesian estimation of spatial filters with Moran's eigenvectors and hierarchical shrinkage priors.” *Spatial Statistics* 38: 100450. [https://osf.io/fah3z/](https://osf.io/fah3z/) Data and code: [https://github.com/ConnorDonegan/ESF](https://github.com/ConnorDonegan/ESF).

Jeffreys, Sir Harold (1961). *Theory of Probability.* Oxford University Press.

Li, Hongfei, Catherine A. Calder, and Noel Cressie (2007). "Beyond Moran's I: testing for spatial dependence based on the spatial autoregressive model." *Geographical Analysis* 39, no. 4: 357-375.

MIT Election Data and Science Lab (2018). "County Presidential Election Returns 2000-2016", URL:https://doi.org/10.7910/DVN/VOQCHQ, Harvard Dataverse, V1.
